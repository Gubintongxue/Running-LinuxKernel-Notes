### 9.4 虚拟内存管理

在 Linux 中，虚拟内存管理至关重要。内核为每个进程创建一个虚拟地址空间，使其仿佛拥有独立的内存资源。这一虚拟内存的实现是通过 **进程地址空间** 和 **内存描述符 (mm_struct)** 数据结构进行管理的。

#### 9.4.1 进程地址空间

进程地址空间是进程可以访问的虚拟地址范围。在 64 位系统中，这个空间最大可达 **256 TB**。进程地址空间的划分包括多个区域，典型的有：

- **代码段**：存放可执行文件的指令。
- **数据段**：存储已初始化和未初始化的数据变量（如 `.data` 和 `.bss` 段）。
- **用户栈**：位于用户空间的最高地址处，从高地址向低地址延伸。
- **MMAP 区域**：用于文件映射或匿名映射，通常由 `mmap` 系统调用创建。
- **堆区**：由 `malloc()` 等分配的动态内存区域。

这些内存区域由内核中的 `vm_area_struct`（简称 VMA）数据结构管理，描述进程中每一块虚拟地址空间，并且不同进程的虚拟地址空间相互隔离，通过独立页表管理，确保同一地址在不同进程中可以映射到不同的物理内存。

#### 9.4.2 内存描述符 mm_struct

==为了有效管理和跟踪每个进程的地址空间，Linux 内核使用 **内存描述符** `mm_struct`。每个进程的 `task_struct` 中有一个 `mm` 指针指向 `mm_struct`，记录进程地址空间的结构信息和状态。`mm_struct` 的定义在 `include/linux/mm_types.h` 中，关键成员包括：==

- **mmap**：指向该进程所有 VMA 的单链表头。
- **mm_rb**：VMA 的红黑树根节点，提供更高效的 VMA 查找。
- **get_unmapped_area**：判断虚拟内存中是否有足够的空间，用于找到未被映射的内存区域。
- **pgd**：==指向用户进程的顶层页表（PGD）。==
- **mm_users**：记录正在使用该进程地址空间的线程数目。
- **mm_count**：==`mm_struct` 的主引用计数。==
- **mmap_sem**：保护进程地址空间的读写信号量。
- **start_code** 和 **end_code**：==代码段的起始和结束地址。==
- **start_data** 和 **end_data**：==数据段的起始和结束地址。==
- **start_brk** 和 **brk**：==堆区域的起始和当前结束地址。==
- **total_vm**：进程地址空间的总大小。

`mm_struct` 提供了用户进程地址空间的整体信息，如图 9.24 所示，它与 `task_struct` 结合，为内核提供进程地址空间的组织和管理。

### 总结

- **进程地址空间** 使用 VMA 进行管理，每块内存区域各自独立、不可重叠，确保进程安全和稳定。
- ==**mm_struct** 描述符用于跟踪每个进程的 VMA 链表、页表、代码段、数据段、堆区、栈区等，帮助内核高效管理和分配内存。==

这种虚拟内存管理机制，使得 Linux 能够灵活管理大量离散的内存请求，为每个进程提供隔离且动态扩展的内存空间，同时保护系统的稳定性和安全性。



### 9.4.3 VMA管理

`VMA` (Virtual Memory Area) 是 Linux 内核中用于描述进程地址空间中内存区域的数据结构。每个用户进程的地址空间由一个或多个 VMA 组成，主要用于管理该进程虚拟内存的映射和属性。VMA 的实现对于内存管理和内核操作至关重要，尤其是在需要频繁内存分配的环境中（如云计算系统）。

#### VMA 数据结构

==VMA 的核心数据结构 `vm_area_struct` 定义在 `mm_types.h` 文件中，关键成员如下：==

- **vm_start 和 vm_end**：指示 VMA 的起始和结束地址，确定了该内存区域的范围。
- **vm_next 和 vm_prev**：用于将进程的多个 VMA 链接成一个单链表。
- **vm_rb**：作为红黑树的节点，内核通过红黑树优化查找和管理多个 VMA，提升效率。
- **vm_mm**：指向 VMA 所属的进程的 `mm_struct`，便于获取进程的整体内存信息。
- **vm_page_prot**：指定该 VMA 的访问权限，例如可读、可写、可执行等。
- **vm_flags**：包含 VMA 的标志位，描述区域的属性。
- **anon_vma_chain 和 anon_vma**：用于管理匿名页面，便于反向映射。
- **vm_ops**：指向一组操作方法的集合，用于在 VMA 中执行特定操作，尤其是文件映射。
- **vm_pgoff**：对于文件映射的偏移量，单位为页面大小 `PAGE_SIZE`。
- **vm_file**：指向文件实例 `file`，描述映射的文件。
- **vm_private_data**：存储与 VMA 相关的私有数据。

#### VMA 与 mm_struct 关系

VMA 是管理虚拟内存块的基本单位，而 `mm_struct` 数据结构则是每个进程的整体内存管理的核心。每个进程的 `task_struct` 结构中的 `mm` 成员指向其 `mm_struct`，而该 `mm_struct` 中有两个重要成员：

- **mmap**：指向进程所有 VMA 的链表头，形成单链表。
- **mm_rb**：红黑树的根节点，用于高效地查找 VMA。

==每个进程的所有 VMA 以起始地址递增的顺序插入到 `mmap` 链表中。对于拥有大量 VMA 的进程（如某些云计算应用），链表查找效率低，因此内核使用红黑树结构来优化，存储在 `mm_rb` 中。==

#### VMA 与进程的关系

在进程运行过程中，==内核根据 `task_struct` 和 `mm_struct` 确定进程的 VMA 结构，==如图所示：

- ==**task_struct** 的 `mm` 指针指向进程的 `mm_struct`，后者包含 `mmap`（VMA 链表）和 `mm_rb`（VMA 红黑树）。==
- ==通过 `mmap` 链表可以遍历进程的所有 VMA，获得该进程的地址空间布局。==
- ==`mm_struct` 的 **pgd** 成员指向进程的页表，为每个进程提供独立的虚拟地址映射。==
- 当进程首次访问 VMA 的某个虚拟地址，若未建立物理页面映射，则触发缺页异常。在异常处理中，内核分配物理页面并填充页表项，建立虚拟地址与物理地址的映射关系。

#### 总结

VMA 管理在 Linux 内核中至关重要：

- ==**VMA 数据结构** 用于描述和控制内存区域的范围、权限和属性。==
- ==**mm_struct** 结合 VMA 的链表和红黑树，提供高效的虚拟内存管理。==
- ==**缺页异常处理** 机制在首次访问时创建页面映射，确保内存访问的正确性与安全性。==

这一结构有效地组织了进程地址空间，支持进程隔离和动态内存分配，优化了系统在多进程和大内存环境下的性能。



### 9.4.4 VMA 属性

`VMA` (Virtual Memory Area) 的 `vm_flags` 成员用来描述虚拟内存区间的各种属性，如可读、可写、共享等。每个 VMA 的这些属性影响内存区域的访问方式和共享特性。表中的 VMA 属性标志位列出了一些常见属性及其含义：

#### 常见的 VMA 属性标志位

- **VM_READ**：可读属性，允许读取该区域的内容。
- **VM_WRITE**：可写属性，允许写入该区域。
- **VM_EXEC**：可执行属性，允许执行该区域的代码。
- **VM_SHARED**：共享属性，允许多个进程共享此区域。
- **VM_LOCKED**：表示锁定该内存区域，即防止其被交换至磁盘。
- **VM_HUGETLB**：用于大页（huge page）的映射，以提高内存管理效率。
- **VM_SEQ_READ** 和 **VM_RAND_READ**：指示应用程序会顺序或随机访问该区域内容。

#### 其他特殊标志位

- **VM_DONTDUMP**：该区域不会包含在核心转储（core dump）文件中，保护敏感数据。
- **VM_UFFD_MISSING** 和 **VM_UFFD_WP**：用于用户态缺页处理和写保护跟踪。
- **VM_SPECIAL**：标记该区域无法合并、扩展或锁定，通常用于特定设备内存区域。

这些 VMA 属性可以任意组合，最终会映射为硬件级的页表项标志。通过 `vm_get_page_prot` 函数，将 `vm_flags` 属性标志转换为与硬件页表项相对应的标志位。

#### VMA 属性到页表项属性的映射

在实际的页表项中，VMA 属性转换为硬件可识别的属性位，主要由 `vm_page_prot` 成员完成。该过程利用了 `protection_map` 数组，其中每个元素表示特定组合的页表项属性，例如 `_P000` 表示无效的页表项属性，`_P001` 表示只读属性，`_P100` 表示可执行属性。

通过 `pgprot_t protection_map[16]` 数组可以快速映射 `vm_flags` 至具体的页表项标志组合，例如：

- **PTE_TYPE_PAGE**：指示这是一个页面条目类型。
- **PTE_AF**：设置访问标志，表示该页面已被访问。
- **PTE_SHARED**：设置共享属性，使得该内存可以被多个处理器缓存共享。
- **PTE_USER**：表示该区域允许用户态访问。
- **PTE_PXN** 和 **PTE_UXN**：分别表示特权模式和用户模式下禁止执行代码，用于增强安全性。

### 处理器相关标志位

每个处理器架构可能有不同的硬件标志来控制内存的访问权限和属性。以 ARM64 为例，通过 `PTE_TYPE_PAGE` 和 `PTE_RDONLY` 等标志设置页面的只读、缓存模式和用户访问权限等，这些硬件标志直接影响到页表项中的控制位。

### 总结

VMA 属性不仅影响应用程序访问内存区域的方式，还直接决定页表项中的权限配置。通过 `vm_flags` 转换为 `vm_page_prot` 的具体硬件标志，内核可以灵活地控制每个虚拟内存区域的访问方式，满足多种应用的需求，包括共享、保护和缓存管理等。





### 9.4.5 VMA查找操作

在 Linux 内核中，查找、插入和合并虚拟内存区域 (VMA) 是管理进程虚拟地址空间的关键操作，主要通过以下接口实现：

#### 1. 查找 VMA

==内核提供 `find_vma` 和 `find_vma_intersection` 等接口函数，通过给定地址查找符合条件的 VMA：==

- **`find_vma`**：根据地址 `addr` 查找包含该地址或其后的第一个 VMA，如果没有找到则返回 `NULL`。这个函数常用于检查地址是否在某一 VMA 范围内。
- **`find_vma_prev`**：类似 `find_vma`，但同时返回找到的 VMA 前继节点。
- **`find_vma_intersection`**：用于查找和特定地址范围（`start_addr` 和 `end_addr`）重叠的 VMA。

这些查找函数会优先在 `mm_struct` 中的红黑树（`mm_rb`）中查找 VMA，以提高查找效率。如图 9.27 所示，`find_vma` 通过红黑树找到包含或紧邻地址的 VMA。

#### 2. 插入 VMA

==**`insert_vm_struct`** 函数用于在 `mm_struct` 的链表和红黑树中插入新的 VMA。==参数包括内存描述符 `mm` 和要插入的 VMA，该操作会更新链表和红黑树中的 VMA 节点，以便内核快速查找和管理进程地址空间。

#### 3. 合并 VMA

==**`vma_merge`** 函数用于检查新的 VMA 是否可以与现存 VMA 合并，减少分散的内存区间。==参数包括新 VMA 的起始地址和结束地址、文件映射相关信息（如 `file` 和 `pgoff`）等。合并操作通常在新 VMA 加入时自动执行，能够优化内存管理并减少 VMA 的数量。

### 9.4.6 `malloc()` 函数

==`malloc()` 是 C 标准库中的内存分配函数，用于分配用户进程的虚拟内存。在系统底层，`malloc()` 依赖内核提供的 `brk` 系统调用进行内存扩展。==以下是关键问题及其解释：

1. **`malloc()` 是否立即分配物理内存？**
   - ==一般来说，`malloc()` 不会立即分配物理内存。只有在实际访问分配的内存（如 `memset` 或读写操作）时，才触发缺页异常，导致内核为这块虚拟内存分配物理页面。==
2. **`malloc(100)` 实际分配的内存大小？**
   - ==内核分配内存时以页面为单位。即便 `malloc()` 请求 100 字节，分配的内存会按页面大小（如 4KB）对齐。==
3. **相同虚拟地址的分配是否会冲突？**
   - 不会发生冲突。每个进程有独立的页表，内核通过不同的页表为各进程管理相同虚拟地址的不同物理页面。

###  `malloc()` 的实现流程

图 9.29 展示了 `malloc()` 的实现流程：

1. **用户进程调用 `malloc()`**：
   - ==首先在用户空间通过 C 标准库的 `malloc()` 调用，进入内核后使用 `brk` 系统调用扩展进程的虚拟地址空间。==
2. **查找和设置新的 `brk` 边界**：
   - `brk` 系统调用根据进程内存描述符 `mm_struct` 中的 `mm_rb` 红黑树，查找或分配合适的 VMA。如果分配失败，则在缺页异常处理机制下动态分配页面。
3. **缺页异常处理**：
   - 当用户进程实际访问 `malloc()` 分配的内存时，CPU 触发缺页异常。内核通过缺页异常处理函数分配物理页面，并将其映射到用户进程的页表中。

通过这些操作，`malloc()` 分配的内存块会在访问时建立页表映射，保障了虚拟地址到物理内存的转换，提高了系统的内存管理效率。

### 9.4.7 `mmap()` 和 `munmap()` 函数

`mmap()` 和 `munmap()` 是 Linux 用户空间中常用的内存管理系统调用，用于文件映射、内存分配和进程间通信等。以下是 `mmap()` 和 `munmap()` 的函数声明：

```
#include <sys/mman.h>
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
int munmap(void *addr, size_t length);
```

#### 参数说明

- **`addr`**：指定映射到进程地址空间的起始地址，通常设为 `NULL`，让内核选择合适的地址。
- **`length`**：映射的大小。
- **`prot`**：设置内存区域的读写权限。
- **`flags`**：控制映射的属性（共享、私有等）。
- **`fd`**：文件描述符，用于文件映射。
- **`offset`**：文件偏移量，适用于文件映射。

#### `prot` 取值

- **`PROT_EXEC`**：可执行。
- **`PROT_READ`**：可读。
- **`PROT_WRITE`**：可写。
- **`PROT_NONE`**：不可访问。

#### `flags` 取值

- **`MAP_SHARED`**：创建共享映射，多个进程可共享修改，修改同步到磁盘。
- **`MAP_PRIVATE`**：创建私有映射，写时复制，修改不会同步到磁盘。
- **`MAP_ANONYMOUS`**：创建匿名映射，未关联文件。
- **`MAP_FIXED`**：强制映射到指定地址，若地址冲突则调用 `do_munmap()` 销毁旧映射。
- **`MAP_POPULATE`**：预读文件内容到映射区域（仅支持私有映射）。

### 映射类型

根据 `fd` 的不同，可以分为匿名映射和文件映射，并可进一步分类为私有或共享映射：

1. **私有匿名映射**：用于大块内存分配（如超过 128KB 时，glibc 使用 `mmap()` 而非 `brk()`）。
2. **共享匿名映射**：用于进程间共享内存（如 `fd = -1` 且 `flags = MAP_ANONYMOUS | MAP_SHARED`）。
3. **私有文件映射**：用于动态库加载（`flags = MAP_PRIVATE`）。
4. **共享文件映射**：用于进程间通信和文件读写。进程间共享的文件映射可以实现共享内存通信，多个进程映射相同文件，能彼此读取写入内容。

### `mmap()` 实现流程

`mmap()` 的实现框架与 `brk` 类似，主要通过 VMA 管理虚拟内存，并在缺页异常时分配物理页面：

1. **系统调用入口**：`mmap()` 进入内核后调用 `do_mmap_pgoff()`，分配合适的地址并设置 `prot` 和 `flags`。
2. **文件或匿名映射的处理**：如果是文件映射，获取文件的 `file` 结构；匿名映射会调用 `shmem_zero_setup()` 打开特殊文件（如 `/dev/zero`）。
3. **VMA 操作**：`do_mmap_pgoff()` 调用 `mmap_region()` 创建 VMA。对共享匿名映射，使用 `shmem` 模块生成匿名共享内存区。
4. **缺页异常处理**：当访问未分配的映射页面时触发缺页异常，缺页异常处理分配物理页面并建立虚拟到物理地址的映射。

### `munmap()` 实现

`munmap()` 用于解除 `mmap()` 创建的映射：

- `munmap()` 调用后，内核释放指定地址范围的 VMA 和物理页面。
- 更新进程的 `mm_struct`，并从页表中移除映射。

### 应用场景和功能

`mmap()` 和 `munmap()` 适用于内存分配、文件读写、动态库加载和进程间共享内存。`mmap()` 的工作机制如图 9.31 所示，结合 VMA 和缺页异常处理实现高效的内存管理，使得用户进程可以灵活操作虚拟内存区域，实现多样化的系统调用应用。

