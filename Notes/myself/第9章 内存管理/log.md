## 9.1 从硬件角度看内存管理

已总结-大致

9.1.1 内存管理的远古时代

1.单道编程，多道编程 2.固定分区，动态分区

固定分区与动态分区的挑战





9.1.2 地址空间的抽象

进程三方面需要内存：进程自身的内存，栈空间，堆空间

虚拟地址请求由mmu进行地址转换为物理地址

虚拟内存的优势



9.1.3 分段机制

分段机制的特点

分段机制的不足：1. 整段换入、换出 2.局部性原理不佳



9.1.4 分页机制

分页机制的工作流程

虚拟地址结构与页表，VA结构分为页表索引部分VPN和page offset



一级页表与多级页表

一级页表需要很大连续内存来存储所有页表项，内存上浪费

四级页表



## 9.2 从软件角度看内存管理

9.2.1 free命令

free -m 以兆字节为单位显示物理内存、交换空间及内核缓存区的详细状态。



9.2.2 从应用编程角度看内存管理

void *malloc(size_t size);         // 分配内存
void free(void *ptr);              // 释放内存
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
int munmap(void *addr, size_t length); // 解除内存映射
int mprotect(const void *addr, size_t len, int prot); // 修改内存保护属性



9.2.3 从内存布局图角度看内存管理

- **用户空间**：虚拟地址范围 `0x0000000000000000` 至 `0x0000ffffffffffff`，供用户进程使用。
- **内核空间**：虚拟地址范围 `0xffff000000000000` 至 `0xffffffffffffffff`，供内核使用。

内核空间布局：

Modules ，vmalloc , fixed, PCI IO ，vmemmap，线性映射区

==这里48位虚拟地址空间为什么不是64位，用到了符号扩展概念，可看疑问补充。==



vmalloc区域有内核映像文件区域

内核地址的特殊符号：**PAGE_OFFSET**：表示物理内存在内核空间的线性映射起始地址，在 ARM64 架构上为 `0xffff800000000000`。

==**vmalloc 区域**：用于内核动态分配虚拟内存，通常不直接映射到物理内存，而是延迟映射。==



9.2.4 从进程角度看内存管理

ELF文件，可执行文件

ELF文件结构，文件头和段头表记录了文件的基本信息和各段的偏移地址。==编译并链接 ELF 文件时，会将同权限的段组织在一起，形成分段（Segment），进程加载时基于这些分段映射至进程地址空间==

/proc文件系统



9.2.5 从内核角度看内存管理

用户空间层：一些系统调用，malloc(),mmap,mlock(),madivse()

内核空间层

1.系统调用处理，sys_brk,sys_mmap,sys_madvise

2.VMA管理

3.缺页中断管理

4.匿名页面和文件缓存页面

5.页面回收 6.反向映射

7.slab分配器

8.页表管理



硬件层:MMU，TLB，高速缓存和DDR内存



## 9.3 物理内存管理

9.3.1物理页面

物理内存的最小管理单元是页面，每个页面通常是4KB

struct page内核管理物理页面，包括flags成员，_refcount和 _mapcount ,mapping字段， 其他字段

Linux 内核为每个物理页面分配一个 `struct page` 结构，并将这些结构存储在 `mem_map` 数组中，实现与物理页面的 1:1 映射。



9.3.2 内存管理区

物理内存被分割成不同的管理区域以满足不同内存需求，称为内存管理区zone。

- **ZONE_DMA**：主要用于 DMA 操作，适用于支持 DMA 的设备（如 x86 架构），它限制设备只能访问物理内存的前 16MB。这在 ARM 架构中不常见。
- **ZONE_NORMAL**：==用于线性映射内存，是内核能直接访问和管理的物理内存区域。==在 32 位系统中，内核可以直接映射的物理内存最大约为 1GB。
- **ZONE_HIGHMEM**：用于管理高端内存，在 32 位系统中常见，因为内核无法直接映射到超过 1GB 的高端内存。高端内存必须通过特定方法（如临时映射）来访问。对于 64 位系统，由于有足够的地址空间，`ZONE_HIGHMEM` 通常不存在。

在 32 位系统中，页表通常直接映射 `ZONE_NORMAL` 和 `ZONE_DMA`，而 `ZONE_HIGHMEM` 需要临时映射才能访问。

64 位系统中页表可以直接映射所有物理内存，不需要 `ZONE_HIGHMEM`，内核可以轻松访问所有物理内存。



内存管理区描述符：Linux 内核使用 `struct zone` 数据结构来描述每个内存管理区，其定义在 `include/linux/mmzone.h` 文件中。`struct zone` 包含三个主要部分：只读域、写敏感域、和统计信息。

struct zone的重要成员包括：

1.watermark：为每个内存管理区定义了三个水位：`WMARK_MIN`、`WMARK_LOW` 和 `WMARK_HIGH`，用于控制页面分配器的行为。在页面分配时，系统会根据当前可用页面的数量与水位的对比来决定是否触发页面回收或是否允许分配。

2.lowmem_reserve：在不同内存管理区之间设置的预留内存量，避免低区内存被高优先级需求耗尽。

3.**zone_pgdat**：指向该管理区所在的内存节点，便于在 NUMA 系统中管理不同的内存节点。



提供一些辅助函数操作和查询内存管理区，这些函数位于 `include/linux/mmzone.h` 文件中，常用函数包括：

- **for_each_zone()**：遍历系统中所有的内存管理区，方便在多个管理区间执行某些统一操作。
- **is_highmem(struct zone \*zone)**：判断一个内存管理区是否为 `ZONE_HIGHMEM` 类型。
- **zone_idx(struct zone \*zone)**：返回该管理区在其所属内存节点中的编号，用于识别特定管理区。



内存管理区的分布与布局优化：`struct zone` 通过缓存行对齐（`cacheline_internodealigned_in_smp`）和填充对齐（`ZONE_PADDING`）的方式，避免缓存伪共享（cache false sharing）。这种对齐方式确保了频繁访问的 `struct zone` 数据结构不会因为共享缓存行而导致性能下降。



9.3.3 分配和释放页面

伙伴系统的算法：通过将内存分割成 2 的幂次方大小的块来进行分配与回收==Linux 将内存块分为 11 个大小不同的区域（`MAX_ORDER` 通常为 11），每个区域包含 2^order 个连续页面。例如，`order=0` 表示分配单个页面，`order=10` 表示分配 1024 个页面（4MB）。==

在伙伴系统中，内存分配器通过维护一个链表数组 `free_area`（大小为 `MAX_ORDER`）记录空闲页块。每个链表保存相应 order 大小的连续空闲页面。当用户请求内存时，分配器会在合适的链表中找到空闲块，切割后分配。如果用户释放的块与相邻块可以合并，系统会将它们合并，形成更大的块，这一过程称为“伙伴合并”。



页面分配函数：

**`alloc_pages(gfp_t gfp_mask, unsigned int order)`**：这是核心的页面分配函数，分配 2^order 个连续页面，并返回首个页面的 `page` 结构。`gfp_mask` 是分配掩码，控制分配行为，`order` 为所需页面块的大小。



分配掩码 GFP Flags

##### 1. 内存管理区修饰符

内存管理区修饰符用于指定页面分配的内存管理区。常见标志位如下：

- **`GFP_DMA`**：从 `ZONE_DMA` 中分配内存，用于需要 DMA 支持的设备。
- **`GFP_HIGHMEM`**：优先从 `ZONE_HIGHMEM` 分配内存，用于高端内存分配。
- **`__GFP_MOVABLE`**：表示页面可以迁移或回收，用于内存规整机制。

##### 3. 水位修饰符

水位修饰符控制是否允许访问紧急预留内存：

- **`__GFP_HIGH`**：高优先级，允许访问紧急内存池。
- **`__GFP_ATOMIC`**：用于中断上下文，不允许页面回收或睡眠操作，优先级高。
- **`GFP_MEMALLOC`**：允许访问所有内存，包括系统预留的紧急内存池。



9.3.4 关于内存碎片化

伙伴系统算法有三个基本条件来确定哪些内存块合并为伙伴。大小相同，地址连续，来自相同的父块。

外碎片化（External Fragmentation）是内存中空闲块分布不连续，导致无法分配大块内存的问题。即便系统有足够的物理内存，总是可能因碎片化问题而无法找到一块连续的物理内存。

为了解决外碎片化，Linux 引入了内存规整（Memory Compaction）技术，通过移动页面将空闲页面聚集到一起。这类似于垃圾收集，将离散的空闲块连成一片以便分配更大的内存块。然而，并非所有页面都可以迁移，例如内核使用的某些关键页面无法移动。



Linux 内核在 2.6.24 版本引入了一种反碎片化机制，即**迁移类型**（Migration Types），用以区分哪些页面可以移动、哪些页面不可移动。根据页面的可移动性，将内存划分为不同类型的区域，确保内存碎片化更少。

不可移动页面，可移动页面，可回收页面



在伙伴系统的 `free_area` 结构中，每个 `order` 块链表依据迁移类型再细分成多个链表（如图 9.20 所示）。每种 `order` 大小的页块链表分为三类（不可移动、可移动、可回收），保证每个链表中的页块属于同一迁移类型。



9.3.5 分配小块内存

因为页面分配以整页（通常4KB）为单位，分配几十字节的小块内存会导致资源浪费。为了解决这一问题，Linux 内核引入了 **slab 分配器**。

slab分配器主要有两个变种：slob，slub

==slab 分配器适合管理反复分配和释放的常用小内存对象（如 `mm_struct` 和 `task_struct`），其核心思想是将内存块视作对象并创建对象缓存池（即 slab），在内存不紧张时预分配一批空闲对象，从而减少频繁的小块内存分配开销。==

slab 分配器提供了一组接口用于创建、销毁 slab 描述符以及分配和释放缓存对象：

- **创建 slab 描述符**：`kmem_cache_create()` 函数，用于创建对象缓存池。
- **释放 slab 描述符**：`kmem_cache_destroy()` 函数，用于销毁对象缓存池。
- **分配缓存对象**：`kmem_cache_alloc()` 函数，从 slab 缓存中分配一个对象。
- **释放缓存对象**：`kmem_cache_free()` 函数，释放对象以供其他使用者再利用。

slab 分配器的设计基于以下几个特点：

- **对象化管理**：将内存块视作对象，支持构造函数（constructor）和析构函数（destructor），在分配和释放时自动初始化和清理对象。
- **对象缓存**：释放后的对象不立即归还系统，而是保留在缓存中，供后续使用。
- **多层缓存池**：每个 CPU 拥有本地缓存池，避免多核间的竞争；内存节点拥有共享缓存池，便于分配时快速查找。
- **减少锁争用**：通过本地对象缓存池降低多核系统中 CPU 间的锁竞争，提高分配效率。

每个 slab 描述符由 `kmem_cache` 数据结构描述，包含了：

- **本地对象缓存池**：每个 CPU 的独立缓存池，减少跨核竞争。
- **共享对象缓存池**：全局缓存池，当本地缓存池为空时，从共享缓存池中获取对象。
- **三类链表**：每个 slab 描述符维护三个链表（`slabs_full`、`slabs_partial`、`slabs_free`），分别表示已满、部分满和空闲的 slab。

slab 内存布局包括三个部分：

1. **着色区**：防止缓存行冲突。
2. **对象区**：包含实际存储的对象。
3. **管理区（freelist）**：管理对象的空闲和分配状态。

slab 分配器包含自动回收机制，当对象缓存池中空闲对象数量超过上限时，系统会主动释放部分对象，并在空闲对象达到极限后销毁相应的 slab。这一过程通过 `cache_reap()` 函数的定时器完成，定期检查并清理不活跃的对象缓存。

**kmalloc** 是内核中常用的内存分配函数，其背后使用 slab 分配器实现，提供按 2 的幂次分配内存块的功能。

可看疑问：slab分配举例。



## 9.4 虚拟内存管理

虚拟内存的实现是通过 **进程地址空间** 和 **内存描述符 (mm_struct)** 数据结构进行管理的。

9.4.1 进程地址空间

进程地址空间是进程可以访问的虚拟地址范围。在 64 位系统中，这个空间最大可达 **256 TB**。

进程地址空间的划分包括多个区域，典型的有：代码段，数据段，用户栈，mmap区域，堆区。

9.4.2 内存描述符

Linux 内核使用 **内存描述符** `mm_struct`。每个进程的 `task_struct` 中有一个 `mm` 指针指向 `mm_struct`，记录进程地址空间的结构信息和状态。`mm_struct` 的定义在 `include/linux/mm_types.h` 中，关键成员包括：

- **mmap**：指向该进程所有 VMA 的单链表头。
- **mm_rb**：VMA 的红黑树根节点，提供更高效的 VMA 查找。
- **get_unmapped_area**：判断虚拟内存中是否有足够的空间，用于找到未被映射的内存区域。
- **pgd**：指向用户进程的顶层页表（PGD）。
- **mm_users**：记录正在使用该进程地址空间的线程数目。
- **mm_count**：`mm_struct` 的主引用计数。
- **mmap_sem**：保护进程地址空间的读写信号量。
- **start_code** 和 **end_code**：代码段的起始和结束地址。
- **start_data** 和 **end_data**：数据段的起始和结束地址。
- **start_brk** 和 **brk**：堆区域的起始和当前结束地址。
- **total_vm**：进程地址空间的总大小。



9.4.3 VMA管理

`VMA` (Virtual Memory Area) 是 Linux 内核中用于描述进程地址空间中内存区域的数据结构。

#### VMA 数据结构

VMA 的核心数据结构 `vm_area_struct` 定义在 `mm_types.h` 文件中，关键成员如下：

- **vm_start 和 vm_end**：指示 VMA 的起始和结束地址，确定了该内存区域的范围。
- **vm_next 和 vm_prev**：用于将进程的多个 VMA 链接成一个单链表。
- **vm_rb**：作为红黑树的节点，内核通过红黑树优化查找和管理多个 VMA，提升效率。
- **vm_mm**：指向 VMA 所属的进程的 `mm_struct`，便于获取进程的整体内存信息。
- **vm_page_prot**：指定该 VMA 的访问权限，例如可读、可写、可执行等。
- **vm_flags**：包含 VMA 的标志位，描述区域的属性。
- **anon_vma_chain 和 anon_vma**：用于管理匿名页面，便于反向映射。
- **vm_ops**：指向一组操作方法的集合，用于在 VMA 中执行特定操作，尤其是文件映射。
- **vm_pgoff**：对于文件映射的偏移量，单位为页面大小 `PAGE_SIZE`。
- **vm_file**：指向文件实例 `file`，描述映射的文件。
- **vm_private_data**：存储与 VMA 相关的私有数据。



#### VMA 与 mm_struct 关系

VMA 是管理虚拟内存块的基本单位，而 `mm_struct` 数据结构则是每个进程的整体内存管理的核心。每个进程的 `task_struct` 结构中的 `mm` 成员指向其 `mm_struct`，而该 `mm_struct` 中有两个重要成员：

- **mmap**：指向进程所有 VMA 的链表头，形成单链表。
- **mm_rb**：红黑树的根节点，用于高效地查找 VMA。

每个进程的所有 VMA 以起始地址递增的顺序插入到 `mmap` 链表中。对于拥有大量 VMA 的进程（如某些云计算应用），链表查找效率低，因此内核使用红黑树结构来优化，存储在 `mm_rb` 中。

#### VMA 与进程的关系

在进程运行过程中，==内核根据 `task_struct` 和 `mm_struct` 确定进程的 VMA 结构，==如图所示：

- ==**task_struct** 的 `mm` 指针指向进程的 `mm_struct`，后者包含 `mmap`（VMA 链表）和 `mm_rb`（VMA 红黑树）。==
- ==通过 `mmap` 链表可以遍历进程的所有 VMA，获得该进程的地址空间布局。==
- ==`mm_struct` 的 **pgd** 成员指向进程的页表，为每个进程提供独立的虚拟地址映射。==
- 当进程首次访问 VMA 的某个虚拟地址，若未建立物理页面映射，则触发缺页异常。在异常处理中，内核分配物理页面并填充页表项，建立虚拟地址与物理地址的映射关系。

9.4.4 VMA属性

#### 常见的 VMA 属性标志位

- **VM_READ**：可读属性，允许读取该区域的内容。
- **VM_WRITE**：可写属性，允许写入该区域。
- **VM_EXEC**：可执行属性，允许执行该区域的代码。
- **VM_SHARED**：共享属性，允许多个进程共享此区域。
- **VM_LOCKED**：表示锁定该内存区域，即防止其被交换至磁盘。
- **VM_HUGETLB**：用于大页（huge page）的映射，以提高内存管理效率。
- **VM_SEQ_READ** 和 **VM_RAND_READ**：指示应用程序会顺序或随机访问该区域内容。



9.4.5 VMA查找操作

查找VMA:内核提供 `find_vma` 和 `find_vma_intersection` 等接口函数，通过给定地址查找符合条件的 VMA

插入VMA:**`insert_vm_struct`** 函数用于在 `mm_struct` 的链表和红黑树中插入新的 VMA。

合并VMA:**`vma_merge`** 函数用于检查新的 VMA 是否可以与现存 VMA 合并，减少分散的内存区间。



9.4.6 malloc()函数

malloc()` 是 C 标准库中的内存分配函数，用于分配用户进程的虚拟内存。

在系统底层，`malloc()` 依赖内核提供的 `brk` 系统调用进行内存扩展。

一般来说，`malloc()` 不会立即分配物理内存。只有在实际访问分配的内存（如 `memset` 或读写操作）时，才触发缺页异常，导致内核为这块虚拟内存分配物理页面。

内核分配内存时以页面为单位。即便 `malloc()` 请求 100 字节，分配的内存会按页面大小（如 4KB）对齐。



malloc的实现流程

1. **用户进程调用 `malloc()`**：
   - 首先在用户空间通过 C 标准库的 `malloc()` 调用，进入内核后使用 `brk` 系统调用扩展进程的虚拟地址空间。
2. **查找和设置新的 `brk` 边界**：
   - `brk` 系统调用根据进程内存描述符 `mm_struct` 中的 `mm_rb` 红黑树，查找或分配合适的 VMA。如果分配失败，则在缺页异常处理机制下动态分配页面。
3. **缺页异常处理**：
   - 当用户进程实际访问 `malloc()` 分配的内存时，CPU 触发缺页异常。内核通过缺页异常处理函数分配物理页面，并将其映射到用户进程的页表中。



9.4.7 mmap()和munmap()函数

`mmap()` 和 `munmap()` 是 Linux 用户空间中常用的内存管理系统调用，用于文件映射、内存分配和进程间通信等。

### `mmap()` 实现流程

`mmap()` 的实现框架与 `brk` 类似，主要通过 VMA 管理虚拟内存，并在缺页异常时分配物理页面：

1. **系统调用入口**：`mmap()` 进入内核后调用 `do_mmap_pgoff()`，分配合适的地址并设置 `prot` 和 `flags`。
2. **文件或匿名映射的处理**：如果是文件映射，获取文件的 `file` 结构；匿名映射会调用 `shmem_zero_setup()` 打开特殊文件（如 `/dev/zero`）。
3. **VMA 操作**：`do_mmap_pgoff()` 调用 `mmap_region()` 创建 VMA。对共享匿名映射，使用 `shmem` 模块生成匿名共享内存区。
4. **缺页异常处理**：当访问未分配的映射页面时触发缺页异常，缺页异常处理分配物理页面并建立虚拟到物理地址的映射。

### `munmap()` 实现

`munmap()` 用于解除 `mmap()` 创建的映射：

- `munmap()` 调用后，内核释放指定地址范围的 VMA 和物理页面。
- 更新进程的 `mm_struct`，并从页表中移除映射。



## 9.5缺页异常

当进程访问未建立虚拟内存与物理内存映射的虚拟地址时，处理器会触发缺页异常。此异常必须由 Linux 内核处理，涉及匿名页面、文件缓存页面、写时复制、私有和共享映射等多种情况。

#### 缺页异常的处理流程

ARMv8 架构将异常分为同步异常（如缺页异常）和异步异常（如中断）。发生缺页异常时，处理器首先跳转到异常向量表。ARM64 的异常向量表定义在 `arch/arm64/kernel/entry.S` 文件中，通过异常类型跳转到相应的处理函数。

- **ESR寄存器**（Exception Syndrome Register）提供异常类型和指令特定信息。
- **FAR寄存器**（Fault Address Register）存储导致异常的虚拟地址。

以 EL1（内核态）下的数据异常为例，当异常发生后，处理器会读取 ESR 寄存器来判断异常类型，最终跳转到核心处理函数 `do_page_fault()` 进行进一步处理。

### `do_page_fault()` 函数

`do_page_fault()` 是处理缺页异常的核心函数，不同架构有相应的实现。其执行流程如图9.33所示，以下为主要步骤：

1. **VMA查找**：首先通过地址查找 `vm_area_struct`，验证该地址是否在进程的有效虚拟地址范围内。如果地址不在 VMA 中，且异常发生在用户模式下，则会发送 `SIGSEGV` 或 `SIGBUS` 信号以终止进程。
2. **页表项检查**：找到对应页表项后，检查 PTE（Page Table Entry）是否存在。如果 PTE 不存在，且是匿名页面，则调用 `do_anonymous_page()` 分配物理页面并建立映射关系；如果是文件映射页面，则调用 `do_fault()` 从文件加载页面。
3. **写时复制处理**：==对于私有映射的页面，在写操作时会触发写时复制，此时调用 `do_wp_page()` 分配一个新的物理页面，并将内容复制到新页面中。==
4. **更新页表**：根据页面类型（匿名页面、文件缓存页面等）选择合适的处理函数（如 `do_swap_page()` 处理交换页面，`do_numa_page()` 处理 NUMA 页面），完成页面的分配和映射关系的建立。
5. **刷新 TLB**：更新页表项内容，并刷新相应的 TLB（Translation Lookaside Buffer）和缓存，确保页表变更后地址转换正常。



### 匿名页面缺页异常

==在 Linux 内核中，没有关联到具体文件的页面称为匿名页面。常见的匿名页面包括通过 `malloc()` 函数分配的内存或使用 `mmap` 创建的匿名映射区域。==当进程访问这些尚未映射的匿名页面时，处理器会触发缺页异常，内核调用 `do_anonymous_page()` 函数来处理。该函数会执行以下步骤：

1. **分配物理页面**：内核通过页面分配器为匿名页面分配物理内存。
2. **初始化页面内容**：新分配的物理页面通常初始化为零，确保没有残留数据。
3. **更新页表**：内核更新相应的页表项，建立虚拟地址与新分配物理页面的映射关系。
4. **刷新 TLB**：为了使映射生效，内核刷新 TLB 以确保地址转换正常。

这种按需分配（Lazy Allocation）策略不仅节约内存资源，还提升了系统性能。

### 文件映射缺页异常

文件映射指的是将文件内容映射到进程地址空间中，使得进程可以通过访问虚拟地址来直接操作文件内容。文件映射页面的缺页异常与匿名页面不同，通常由 VMA 的 `fault()` 方法来处理。`fault()` 方法在 `vm_operations_struct` 结构体中定义，当文件映射页面不在内存中且被访问时，内核调用此方法处理缺页异常。

### 写时复制缺页异常

写时复制（Copy-On-Write，COW）是一种推迟数据复制的优化技术，主要用于 `fork` 系统调用。当内核为子进程创建地址空间时，它会将父进程的页面映射到子进程，但设置为只读属性。这样，父子进程可以共享同一物理页面，直到其中一方需要写入该页面，才触发 COW 操作。

在写时复制的缺页异常处理中，`do_wp_page()` 是关键的处理函数，其处理流程如下：

1. **检测写入需求**：`do_wp_page()` 检查页面是否需要写入，确保只读的页面被写入时触发写时复制。
2. **分配新页面**：为需要写入的进程分配一个新的物理页面。
3. **数据复制**：将旧页面内容复制到新页面，保证写入不会影响父子进程的独立数据。
4. **更新页表**：重新设置页表项，将新页面映射到进程的虚拟地址，并修改页面属性为可写。
5. **刷新 TLB**：内核刷新 TLB，确保地址变更立即生效。



缺页异常的例子可见疑问。



## 9.6 内存短缺

9.6.1 页面回收算法

LRU算法

第二次机会算法

页面回收流程

页交换

9.6.2 OOM killer机制

OOM Killer 通过以下策略选择进程：

- **高内存占用**：优先选择占用大量内存的进程。
- **低优先级进程**：优先选择对系统影响小的后台进程，而非系统关键进程。
- **可调节性**：通过 `oom_score_adj` 和 `oom_adj` 进一步调整特定进程的优先级，使关键进程如系统服务和守护进程不被 OOM Killer 选中。



内存压力大时内存分配，slowpath或者触发oom的例子请看疑问。



## 9.7 内存管理日志信息以及调试信息

### 9.7.1 `vm_stat` 计数

内核定义了三个主要的 `vm_stat` 计数器，用于内存管理的不同层次的统计：

1. **`vm_zone_stat`**：与 `zone` 相关的页面计数，用于统计内存管理区的页面使用情况。
2. **`vm_numa_stat`**：与 NUMA（非一致性内存访问）相关的页面计数，反映各个 NUMA 节点的内存分布。
3. **`vm_node_stat`**：与内存节点相关的页面计数，主要用于统计内存节点的页面情况。

此外，`zone` 数据结构中还包含与页面相关的统计计数

同样地，在 `pglist_data` 数据结构（用于描述内存节点）中也定义了页面统计计数

### 页面计数接口函数

内核提供了一些接口函数，用于管理页面计数的增加、减少和读取操作：

- **`zone_page_state_add()`**：将指定类型的页面计数 `x` 增加到 `zone` 中的 `vm_stat` 数组以及全局 `vm_zone_stat` 数组。
- **`node_page_state_add()`**：将指定类型的页面计数 `x` 增加到内存节点的 `vm_stat` 数组和全局 `vm_node_stat` 数组。
- **`global_zone_page_state()`**：读取全局 `vm_zone_stat` 数组中的指定类型的页面计数。
- **`global_node_page_state()`**：读取全局 `vm_node_stat` 数组中的指定类型的页面计数。
- **`inc_zone_page_state()`**：增加内存管理区的指定类型页面的计数。
- **`dec_zone_page_state()`**：减少内存管理区的指定类型页面的计数。

这些函数简化了页面计数的管理，使内核在内存管理过程中能动态监控并调整页面的分配和释放情况。

### 调试和日志信息

通过以上计数器和接口函数，内核能有效追踪页面的分配和释放情况，帮助开发者在内存管理的调试中发现问题，例如内存泄漏或页面回收效率低下等问题。同时，内核可以通过日志输出这些计数信息，为运维人员和开发者提供关于内存使用和页面状态的实时数据，以更好地分析和优化系统性能。



### 9.7.2 `meminfo` 分析

在 Linux 系统中，`/proc/meminfo` 文件提供了详细的系统内存使用信息，是了解系统内存状态的主要途径。该文件的内容是动态生成的，通过 `meminfo_proc_show()` 函数在 `fs/proc/meminfo.c` 中实现，内容涵盖了物理页面的使用情况、缓存、交换分区等多个方面。



### 9.7.3 伙伴系统信息

在 Linux 内核中，通过 `/proc/buddyinfo` 和 `/proc/pagetypeinfo` 节点可以获取当前系统的伙伴系统信息，帮助开发者了解各类页面的分布和迁移类型。

- **`/proc/buddyinfo`**：提供当前系统中伙伴系统的基本信息，展示每个 `zone` 中不同 `order`（页面数的指数，表示连续页面块的大小）下的空闲页面数。
- **`/proc/pagetypeinfo`**：提供更详细的伙伴系统信息，包括迁移类型（如 `Unmovable`、`Movable`、`Reclaimable`、`CMA`、`HighAtomic`、`Isolate`）的页面分布以及各个 `order` 下每种迁移类型的页面数量。图 9.35 展示了一个例子，表明当前系统在 `DMA32` 区域内，`Movable` 迁移类型的页面数量最多。



### 9.7.4 查看内存管理区的信息

在 Linux 系统中，通过 `/proc/zoneinfo` 节点可以查看所有内存管理区（`zone`）的详细信息。该节点展示了系统中各个内存管理区的使用情况，包括页面数量、水位等信息，对内存调优和系统状态分析非常有用。



### 9.7.5 查看进程相关的内存信息

在 Linux 系统中，可以通过 `mm_struct` 数据结构中的 `rss_stat` 成员来查看进程的内存使用情况，包括文件映射页面、匿名页面、交换页面以及共享内存页面等。





### 9.7.6 查看系统内存信息的工具

Linux 提供了一些常用工具来监控系统内存使用情况，包括 `top` 和 `vmstat`。