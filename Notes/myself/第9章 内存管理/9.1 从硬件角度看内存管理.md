# 第9章 内存管理

内存管理是操作系统中的核心模块之一，其复杂性主要源于硬件与软件紧密结合的特点。随着计算机技术的发展，从简单的内存管理到现代的分页机制，内存管理的实现不断演进。以下是第9章内存管理硬件方面的详细总结。

------

## **9.1 从硬件角度看内存管理**

内存管理需要结合硬件和软件技术共同实现，尤其涉及如何将程序在内存中的组织形式抽象并进行有效管理。

------

### **9.1.1 内存管理的“远古时代”**

1. **单道编程**：

   - 只有一个用户进程和操作系统运行，程序直接使用物理地址，不涉及复杂的内存管理。
   - 缺点：
     - 程序不能超过物理内存大小。
     - 系统只能运行一个程序，导致资源浪费。
     - 程序无法在不同机器间迁移。

2. **多道编程**：

   - 同时运行多个进程，采用两种分区方式：
     - 固定分区：
       - 在系统编译时划分固定大小的内存分区，每个分区用于一个进程。
       - 缺点：地址空间不可动态扩展，程序大小必须匹配分区。
     - 动态分区：
       - 按需从剩余内存中分配与进程大小一致的空间，但会出现**内存碎片**。

   **动态分区内存碎片的示例：**

   - 操作系统预留4MB内存，其余部分供进程使用。
   - 多个进程加载和换出后，会形成内存空洞（如图9.1所示）。
   - 解决碎片化的方案：进程迁移，但此过程非常耗时。

3. **内存管理的问题**：

   - **地址空间保护问题**：进程之间可以互相访问内存，存在安全隐患。
   - **内存使用效率低**：频繁换出、换入导致系统性能低下。
   - **地址重定位问题**：进程换入换出时地址不固定，需使用重定位技术。

------

### **9.1.2 地址空间的抽象**

内存管理通过**虚拟内存**概念解决上述问题：

1. 虚拟内存：
   - 进程通过虚拟地址访问内存，由**处理器的MMU**将虚拟地址转换为物理地址。
   - 解决问题：
     - **隔离性与安全性**：进程A无法访问进程B的物理内存。
     - **效率提升**：减少动态分区中的内存碎片。
     - **重定位简化**：进程使用统一的虚拟地址，无需关心物理地址。

------

### **9.1.3 分段机制**

1. **概念**：
   - 将进程的虚拟地址映射到物理地址空间，不同进程占用的地址互不重叠。
   - 若进程访问未映射的地址，会触发**缺页异常**，操作系统负责处理。
2. **优缺点**：
   - **优点**：实现地址空间的隔离，程序可在不同系统间迁移。
   - **缺点**：内存利用率低，当内存不足时需将整个进程换出到磁盘。
     - 进程在运行时，根据**局部性原理**，只有一部分数据一直在使用，若把那些不常用的数据交换出磁盘，就可以节省很多系统带宽，而把那些常用的数据驻留在物理内存中也可以得到比较好的性能

补充：局部性原理

局部性原理是指[CPU](https://baike.baidu.com/item/CPU/120556?fromModule=lemma_inlink)访问[存储器](https://baike.baidu.com/item/存储器/1583185?fromModule=lemma_inlink)时，无论是存取指令还是存取数据，所访问的[存储单元](https://baike.baidu.com/item/存储单元/8727749?fromModule=lemma_inlink)都趋于聚集在一个较小的连续区域中。

三种不同类型的局部性:

[时间局部性](https://baike.baidu.com/item/时间局部性/56138378?fromModule=lemma_inlink)（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。

[程序循环](https://baike.baidu.com/item/程序循环/50886238?fromModule=lemma_inlink)、[堆栈](https://baike.baidu.com/item/堆栈/1682032?fromModule=lemma_inlink)等是产生时间局部性的原因。

[空间局部性](https://baike.baidu.com/item/空间局部性/56102310?fromModule=lemma_inlink)（Spatial Locality）：在最近的将来将用到的信息很可能与正在使用的信息在空间地址上是临近的。

顺序局部性（Order Locality）：在典型程序中，除转移类指令外，大部分指令是顺序进行的。[顺序执行](https://baike.baidu.com/item/顺序执行/332454?fromModule=lemma_inlink)和非顺序执行的比例大致是5:1。此外，对大型数组访问也是顺序的。

指令的顺序执行、数组的连续存放等是产生顺序局部性的原因。

------

### **9.1.4 分页机制**

1. **概念**：

   - 将虚拟地址空间划分为固定大小的页面，每页大小通常为4KB。
   - 程序使用时，仅访问和修改的部分虚拟内存会被映射到物理页面（**请求调页**）。

2. **虚拟地址与物理地址映射**：

   - 虚拟地址

     由两部分组成：

     - 页偏移量（如VA[11:0]）决定页面内的具体位置。
     - 虚拟页帧号（VPN）用于定位页表中的页表项。

   - **页表**记录虚拟页帧号（VPN）与物理页帧号（PFN）的映射关系。

3. **页表结构与查询过程**（如图9.3所示）：

   - **一级页表**：直接映射整个虚拟地址空间，但占用内存过多（4MB）。
   - 多级页表：
     - 将页表分为**一级页表**和**二级页表**，减少页表占用的物理内存。

   **ARMv7-A二级页表查询过程**：

   - 虚拟地址的VA[31:20]用于索引一级页表，找到相应的页表项。
   - VA[19:12]用于索引二级页表，找到物理页面的地址。

------

#### **代码示例：一级页表与二级页表结构**

```C
// 页表项结构体示例
struct page_table_entry {
    unsigned int valid : 1;  // 有效位
    unsigned int pfn : 20;   // 物理页帧号
    unsigned int flags : 11; // 页表项标志位（脏页、可读写等）
};

// 一级页表查询示例
unsigned int vpn = (virtual_address >> 12) & 0xFFFFF;
struct page_table_entry *pte = &page_table[vpn];

// 检查有效位是否为1，若无效则触发缺页异常
if (!pte->valid) {
    handle_page_fault(virtual_address);
} else {
    // 计算物理地址
    unsigned int physical_address = (pte->pfn << 12) | (virtual_address & 0xFFF);
}
```

#### 补充：为什么64位操作系统只有48位虚拟地址空间？

虽然64位处理器**理论上**可以支持 2^{64} 个地址（即约16 EB, exabytes），但目前主流的64位操作系统和硬件架构通常只启用了**48位的虚拟地址空间**。这背后的原因涉及硬件设计、性能优化、软件管理和安全性。

------

##### **1. 页表的复杂性和存储开销**

- **多级页表的存储需求**：
  - 在64位系统中，每增加1位地址位宽会显著增加页表的大小。如果启用64位地址空间，页表的层级和所需的内存将大幅度增加，导致性能下降。
  - 48位虚拟地址空间已经对应**256 TB**的地址空间，足以满足当前和未来一段时间内的需求。
- **页表结构的限制**：
  - ==在x86-64架构中，CPU使用了**四级页表**来管理虚拟地址空间。如果启用完整的64位地址空间，需要**六级页表**，这会极大增加访问虚拟地址时的延迟和页表管理的复杂度。==

------

##### **2. CPU与MMU的设计**

- **地址空间分段和逐步扩展**：
  - **x86-64处理器**最初只支持48位虚拟地址，并计划未来逐步扩展至57位（目前有些ARM64系统支持57位）。这种逐步扩展策略既简化了硬件设计，又确保了未来可以根据需求扩展地址空间。
- **虚拟地址符号扩展**：
  - ==在x86-64架构中，48位虚拟地址使用**符号扩展（sign extension）**填充剩余的64位地址。也就是说，有效地址的高16位要么全为0，要么全为1，用于区分内核地址空间和用户地址空间。==这种机制简化了地址转换，并避免了误用高位地址空间。

------

##### **3. 256 TB虚拟地址空间已经足够**

- **当前应用的需求**：
  - 256 TB的虚拟地址空间足以满足绝大多数应用场景，如数据库、大型科学计算和虚拟化等。即使是**大型服务器和云计算**环境，也难以耗尽如此巨大的虚拟地址空间。
- **物理内存的限制**：
  - 当前服务器和计算设备的物理内存通常在数百GB至数TB之间，远低于256 TB的虚拟地址限制。因此，启用超过48位的虚拟地址空间没有实际意义。

------

##### **4. 节省硬件资源与提升性能**

- **TLB（Translation Lookaside Buffer）的效率**：
  - TLB是用于加速虚拟地址到物理地址转换的缓存。如果启用更多的地址位宽，会导致TLB缓存的压力增大，并增加地址转换的开销。
  - ==使用48位地址空间可以有效减少TLB的开销，并提升内存访问性能。==
- **缓存友好性**：
  - 硬件和操作系统开发者发现，将虚拟地址空间限制为48位可以减少不必要的内存碎片，并提高缓存命中的概率，进而提升系统性能。

------

##### **5. 兼容性与操作系统管理的复杂性**

- **软件适配与兼容性问题**：
  - ==如果启用完整的64位虚拟地址，操作系统和许多应用程序需要进行大量的修改和测试，尤其是涉及**指针和内存管理**的部分。==
- **安全性和内存布局的优化**：
  - ==现代操作系统利用虚拟地址空间的稀疏性来实现**地址空间布局随机化（ASLR）**等安全机制。如果启用完整的64位地址空间，管理这些稀疏空间的复杂性将会急剧增加。==

------

##### **总结**

64位操作系统使用**48位虚拟地址空间**的原因主要是出于**硬件设计的简化、性能优化、页表开销的控制**以及**安全性和兼容性**的考虑。256 TB的虚拟地址空间已经足够应对目前的需求，而启用完整的64位虚拟地址空间会显著增加系统的复杂性和资源开销。随着未来技术的发展和需求的增长，地址空间可能会进一步扩展（例如57位），但目前启用48位已是最合理的选择。

------

#### **ARM64的四级页表**

在ARM64架构下，分页机制进一步扩展为四级页表，每级页表逐步映射到更细粒度的地址空间，减少页表在内存中的占用。

------

# expert总结

### 第9章 内存管理

内存管理模块是操作系统中最复杂的部分之一，涉及从硬件到软件的多层次管理机制。通过分段、分页等机制，系统不仅能有效分配内存，还能保障进程间的隔离与保护。硬件的发展使得内存管理技术不断演进，以支持系统的性能和安全需求。

### 9.1 从硬件角度看内存管理

#### 9.1.1 内存管理的“远古时代”

在操作系统出现之前，计算机程序在卡片上逐条运行，效率低下。后来出现了存储程序的概念，程序在内存中加载后再执行。这一概念的出现，为操作系统的发展奠定了基础，推动了固定分区、动态分区等内存管理思想的产生。

- **单道编程**：整个系统只有一个用户进程和一个操作系统，用户程序始终加载到相同的内存地址，内存管理简单，使用的是物理地址，没有保护机制。缺点是内存无法充分利用，无法同时运行多个程序，不能迁移至不同的硬件平台。
- **多道编程**：系统能够同时运行多个进程。多道编程的内存管理模式出现了**固定分区**和**动态分区**。
  - **固定分区**：内存在编译时划分成多个静态分区，程序被装入合适大小的分区。此方法简单，但缺乏灵活性。
  - **动态分区**：按需为每个进程分配内存，避免固定分区的限制。然而随着进程的换入和换出，内存会产生碎片，降低利用率。

动态分区方法虽然灵活，但容易产生内存碎片。解决碎片化需要进行内存整理，重新分配连续的内存区域。然而，这种重分配会造成很大开销。

#### 固定分区与动态分区的挑战

1. **进程地址空间保护**：在早期模型中，所有进程共享整个物理内存，导致恶意或错误的内存访问风险。
2. **低内存利用率**：进程的换入换出导致频繁的内存操作，效率低下。
3. **地址重定位**：进程每次运行的地址不同，需使用重定位技术以适应不同的内存位置。

由于以上问题无法在操作系统层面完全解决，处理器引入了分段和分页机制，实现更高效的内存管理。



### 9.1.2 地址空间的抽象

在内存管理中，进程通常需要在以下三方面使用内存：

1. **进程自身的内存**：包括代码段和数据段，用于存储程序的指令和数据。
2. **栈空间**：保存函数调用关系、局部变量、函数参数以及返回值等运行时数据。
3. **堆空间**：用于程序运行时的动态内存分配，例如存储动态创建的数据结构。

在直接使用物理内存的系统中，程序需要精确控制这些内存区域的物理地址和大小，增加了开发复杂性。而现代系统对内存进行了**地址空间抽象**，将这些内存区域整合为一个**进程地址空间**或**虚拟内存**。通过虚拟内存，进程不再需要关心物理内存的位置或空间限制，只需请求所需的内存，实际的地址映射由处理器完成。这个过程中，**虚拟地址**被转换为**物理地址**，这一转换称为**地址转换**。

图 9.2 展示了这一抽象：虚拟地址请求由处理器中的**MMU（内存管理单元）**进行地址转换，从而使得每个进程感觉自己拥有整个地址空间的控制权。

#### 虚拟内存的优势

虚拟内存提供了几项关键优势，使操作系统可以更高效、更安全地管理进程内存：

- **隔离性和安全性**：虚拟内存将每个进程的地址空间相互隔离，一个进程无法直接访问其他进程的内存。处理器在内存转换时将进程 A 的请求限制在其自身的地址空间中，确保了数据的安全性。
- **效率**：通过引入分页机制，虚拟内存减少了动态分区中因内存碎片化而带来的效率问题。页式内存管理将内存分成固定大小的页，提升了内存分配与释放的灵活性。
- **重定位简化**：虚拟内存屏蔽了物理内存的实际地址，进程在换入换出时依然可以使用相同的虚拟地址，从而避免了动态分区中繁杂的地址重定位问题。

通过虚拟内存抽象，操作系统将内存管理虚拟化，与进程的虚拟 CPU 以及文件系统的存储抽象共同构成了操作系统的三大核心功能。



### 9.1.3 分段机制

在**分段机制**（segmentation）中，操作系统通过将程序的虚拟地址空间映射到物理内存，实现了进程地址空间的隔离和保护。其主要思想是将进程的地址空间分为不同的段（segment），并为每个段分配物理内存中的不同区域。进程访问虚拟地址空间时，由 CPU 将虚拟地址转换为对应的物理地址。

#### 分段机制的主要特点

- **地址空间隔离**：每个进程的虚拟地址空间被映射到不同的物理地址区域，因此不会出现地址空间的重叠问题。进程 A 和进程 B 在物理内存中彼此隔离，即使它们的虚拟地址空间相似，也不会冲突。
- **越界访问检测**：如果进程试图访问不属于自己的地址空间，或未映射的地址区域，CPU 会捕捉到这种越界访问并发出异常。这一异常通常由操作系统处理，并生成适当的错误提示或采取缺页处理机制。
- **跨系统迁移的便利**：因为进程直接访问的是虚拟地址而非实际物理地址，它们可以在不同系统之间轻松迁移，而无需考虑具体物理内存的布局。

#### 分段机制的实现方法

在分段机制中，**虚拟地址**需要通过 CPU 进行转换，以映射到物理地址。这种虚拟到物理的地址转换使得进程的地址空间隔离成为可能，同时操作系统仅需管理虚拟和物理地址之间的映射关系。

#### 分段机制的不足

虽然分段机制提供了虚拟内存的基本功能，但其内存使用效率较低，原因如下：

- **整段换出/换入**：当物理内存不足时，分段机制仍然需要将整个进程段换出到磁盘，即便其中的大部分数据并不经常被访问。这导致了较多的磁盘 I/O 操作，影响系统性能。
- **局部性原理不佳**：分段机制没有充分利用**局部性原理**。进程在运行时往往只会频繁使用部分数据，而分段机制无法仅将这些数据常驻内存。这种缺陷带来了内存和 I/O 资源的浪费。

为了更高效地利用内存，分段机制之后引入了**分页机制（paging）**，该机制允许按小块单位（即“页”）进行换出/换入，极大提升了系统内存使用效率。



### 9.1.4 分页机制

随着程序对内存需求的不断增加，**分页机制**成为了解决物理内存不足问题的一种有效方式。分页机制的核心思想是**引入虚拟存储器**，使得程序仅需将正在使用的部分保留在物理内存中，其他部分可以交换到磁盘中，达到更高效的内存使用目的。

分页机制通过虚拟地址空间和物理地址空间的分离，让操作系统能够灵活地管理内存。一个程序在运行时的虚拟地址空间由处理器的位宽决定，例如，32位处理器可以提供4GB的虚拟地址空间，64位处理器则可以达到数百TB。

#### 分页机制的工作流程

1. **虚拟地址到物理地址转换**：启用分页机制的处理器直接使用虚拟地址，而不是物理地址。虚拟地址会先通过**内存管理单元（MMU）**转换为物理地址，随后再由内存控制器进行实际存取操作。
2. **页面与页帧**：虚拟地址空间和物理地址空间都被划分为大小一致的页面块。虚拟地址空间的基本单位称为**页面**，物理内存的对应单位为**页帧**。典型的页面大小为4KB，一些处理器还支持更大的页面尺寸，例如16KB、64KB，甚至2MB。
3. **请求调页**：当程序请求访问某个虚拟页面时，如果该页面当前未映射到物理内存中，会触发**缺页异常**。操作系统根据缺页请求从磁盘中加载该页面到物理内存的页帧中，完成映射关系。

#### 虚拟地址结构与页表

以32位处理器和4KB页面为例，虚拟地址（VA）结构可分为**页表索引部分（VPN）\**和\**页面内偏移量（page offset）**。其中：

- VA[11:0]表示页面内的偏移量。
- VA[31:12]用于确定虚拟页帧号（VPN），指向页表中的某个条目。

页表项（PTE）记录了虚拟页帧号到物理页帧号（PFN）的映射关系以及页面属性（如有效位、只读/可写位）。MMU利用页表完成虚拟地址到物理地址的转换。

#### 一级页表与多级页表

**一级页表**是最简单的实现方式，将所有页表项放入一张表。对于32位地址空间和4KB页面，一级页表需要4MB大小的连续内存来存储所有页表项，这在内存使用上过于浪费。因此，多数操作系统采用**多级页表**，例如二级、三级或四级页表，逐级索引，按需加载不同级别的页表，提高内存效率。

- **二级页表结构**：虚拟地址分成多个索引，逐层查找：
  - VA[31:20]用于一级页表索引，定位二级页表的地址。
  - VA[19:12]用于二级页表索引，找到具体的物理页帧。
- **页表填充**：处理器执行程序时，如果二级页表尚未加载到内存，缺页异常会触发分配对应的页表项。这样无需预先加载完整的页表，提高了内存利用率。

#### 页表查询示例

以二级页表为例，页表查询步骤如下：

1. 使用页表基地址寄存器（TTBR）指向一级页表。
2. 根据 VA[31:20] 在一级页表中找到二级页表的物理基地址。
3. 使用 VA[19:12] 在二级页表中定位目标页帧的物理基地址。
4. 根据页内偏移量（VA[11:0]）确定最终物理地址。

**多级页表**如 ARM64 的四级页表，进一步分层以减少单表的内存需求，并在需要时动态加载对应的页表项。

分页机制通过多级页表和按需加载实现高效的内存管理，为操作系统在处理内存不足的问题上提供了强大的工具。





## ==原文：==

![image-20241021102720664](image/image-20241021102720664.png)

![image-20241021102731001](image/image-20241021102731001.png)

![image-20241021102804824](image/image-20241021102804824.png)

![image-20241021102817027](image/image-20241021102817027.png)

------

### 补充：VA[31:20]含义

在 **ARMv7-A 架构**中，使用**二级页表**进行虚拟地址到物理地址的转换时，虚拟地址（**VA**）被分解成不同的段，每段用于不同层级的页表索引。下面详细解释如何从虚拟地址（VA）提取**VA[31:20]**，并用于**一级页表索引**。

------

### **虚拟地址结构解析：ARMv7-A 二级页表**

一个 **32 位虚拟地址（VA）\**可以表示\**4 GB**的虚拟地址空间。ARMv7-A 分为 **两级页表**：**一级页表**和**二级页表**，用于查找最终的物理页帧地址。其结构如下：

- **VA[31:20]**：用于一级页表索引。
- **VA[19:12]**：用于二级页表索引。
- **VA[11:0]**：用于物理页内的偏移（offset）。

------

#### **虚拟地址分解的结构**

假设一个虚拟地址 VA=0x1234ABCDVA = 0x1234ABCDVA=0x1234ABCD，我们将其二进制形式展示如下：

```
VA (32 位): 0001 0010 0011 0100 1010 1011 1100 1101
            └───┬──────┘ └───────┬───────┘ └───┬──────┘
                一级页表           二级页表        页内偏移
                [31:20]           [19:12]        [11:0]
```

具体字段含义如下：

1. VA[31:20]

   （12 位）：

   - 一级页表索引：决定一级页表中要访问的条目。

2. VA[19:12]

   （8 位）：

   - 二级页表索引：决定二级页表中具体要访问的条目。

3. VA[11:0]

   （12 位）：

   - 页内偏移：决定页帧中的具体位置。

------

#### **如何计算 VA[31:20]：**

1. **虚拟地址（VA）**是一个32位数，比如：`VA = 0x1234ABCD`。

2. 将 

   ```
   VA
   ```

    转换为二进制形式：

   ```
   0001 0010 0011 0100 1010 1011 1100 1101
   ```

3. 取 VA 的 [31:20] 位

   作为一级页表索引：

   ```
   VA[31:20] = 0001 0010 0011
             = 0x123 （十六进制）
   ```

4. **将 0x123 作为索引**，它指向一级页表中的第 291 项（十进制：291）。

------

#### **计算一级页表大小：**

- **一级页表**共有 **4096 项**，每项占 **4 字节**：

  ```
  4096 * 4 字节 = 16 KB
  ```

- 一级页表存储在**16 KB**的连续内存中，`VA[31:20]` 索引对应一级页表的某个条目。

------

#### **从一级页表到二级页表的过程：**

1. **CR3 寄存器（或 TTBR0 寄存器）**存储一级页表的基地址。例如：`0x1000`。
2. **VA[31:20]** 用来在一级页表中找到对应的 **二级页表的物理地址**。
3. 在对应的二级页表中，**使用 VA[19:12]** 进一步找到具体的页表条目。
4. 最后使用 **VA[11:0]** 作为页内偏移，确定物理页帧内的具体地址。

------

#### **示例计算**

假设：

- **CR3 = 0x1000**（一级页表基地址）。
- 虚拟地址：`VA = 0x1234ABCD`

1. 从 CR3 找到一级页表：

   ```
   一级页表基地址 = 0x1000
   ```

2. VA[31:20] = 0x123，表示一级页表中的第 291 项：

   ```
   一级页表项地址 = 0x1000 + (0x123 * 4) = 0x148C
   ```

3. **查找二级页表地址**，假设条目中存储了物理地址 `0x2000`（即二级页表基地址）。

4. 使用 VA[19:12] = 0x34

    在二级页表中查找：

   ```
   二级页表项地址 = 0x2000 + (0x34 * 4) = 0x2134
   ```

5. 最后，查找到具体的物理页帧，使用 **VA[11:0]** 作为偏移。

------

#### **总结**

在 ARMv7-A 的二级页表体系中：

1. **VA[31:20]**：用于索引一级页表条目，找到对应的二级页表地址。
2. **VA[19:12]**：用于索引二级页表条目，找到最终的物理页帧地址。
3. **VA[11:0]**：用于页内偏移。

整个过程确保了**虚拟地址的高效映射**到物理地址，并支持进程地址空间的隔离和管理。



------

### 补充：VFN的分配

**VFN (Virtual Frame Number)** 是虚拟内存管理中的一个概念，通常指**虚拟地址空间中的页号**。VFN 是通过将虚拟地址按页大小对齐并去除页内偏移后计算得到的，因此它不是随机分配的，而是由操作系统根据**虚拟内存地址映射策略**决定的。下面详细说明：

------

#### **1. VFN 计算：**

- **虚拟地址**（Virtual Address）由页号和页内偏移组成。

- VFN 由虚拟地址的高位部分表示，低位部分用于页内偏移。

  **计算公式：**
  VFN=Virtual AddressPage Size\text{VFN} = \frac{\text{Virtual Address}}{\text{Page Size}}VFN=Page SizeVirtual Address​

------

#### **2. VFN 的分配原则：**

- **非随机分配**：操作系统不会随意或随机分配 VFN。相反，它会基于进程的内存需求、映射策略和内存布局进行分配。

**具体映射方式：**

1. **线性分配：**

   - 系统为一个进程的代码段、数据段、栈、堆等内存区域按需连续映射到虚拟地址空间，保证它们之间的逻辑顺序。

2. **分区分配：**

   - 栈、堆、代码段等被放置在

     不同的虚拟地址范围

     。例如：

     - 栈通常位于高地址，从高地址向低地址扩展。
     - 堆则从低地址向高地址增长。

3. **需求分页 (Demand Paging)：**

   - 只有在进程真正访问某个虚拟页时，操作系统才会分配物理页，并在页表中建立映射关系。

4. **共享与文件映射：**

   - 通过 `mmap()` 等系统调用，文件的内容可以映射到虚拟地址空间，生成相应的 VFN。

------

#### **3. 操作系统如何管理 VFN：**

- **每个进程**有独立的页表，用于管理虚拟地址和物理地址之间的映射关系。
- **MMU (Memory Management Unit)** 会根据页表，把虚拟地址中的 VFN 转换为对应的物理页号（PFN, Physical Frame Number）。

------

#### **4. 总结：**

VFN 不是随机分配的，而是由操作系统根据**内存管理策略**来分配和管理。每个进程的虚拟地址空间是独立的，且操作系统会确保地址空间的逻辑布局。

------

## 补充：举例说明

让我们更详细地拆解**四级页表地址转换过程**，并通过示例逐步分析从虚拟地址到物理地址的映射过程。

------

### **四级页表映射过程：从虚拟地址到物理地址的详细步骤**

假设：

- **虚拟地址**：`0x0000_0123_4567_89AB`
- 页大小：**4KB** (2¹² 字节)
- 每级页表条目：**512 个**（9 位索引，2⁹ = 512）
- 页表基地址在 **CR3** 寄存器中存储

页表结构如下：

```
| PGD (9 bits) | PUD (9 bits) | PMD (9 bits) | PTE (9 bits) | Offset (12 bits) |
```

虚拟地址（`0x0000_0123_4567_89AB`）拆分如下：

```
PGD 索引：  0x000  
PUD 索引：  0x001  
PMD 索引：  0x091  
PTE 索引：  0x089  
页内偏移：  0xAB  
```

------

#### **步骤 1：从 PGD 表获取 PUD 表地址**

1. **CPU 从 CR3 寄存器读取 PGD 表的物理地址**。
   - **假设**：CR3 寄存器中的 PGD 表基地址为 `0x1000`。
2. **访问 PGD 表**：PGD 表存储在物理地址 `0x1000` 开始的内存区域，每个 PGD 条目占用 **8 字节**。
3. **通过 PGD 索引计算偏移量**：
   - PGD 索引为 `0x000`，因此偏移量是：`0x000 * 8 = 0x0`。
   - **地址计算**：PGD 表地址 + 偏移量 = `0x1000 + 0x0 = 0x1000`。
4. **读取 PGD 表中的条目**：
   - 从 `0x1000` 处读取 **8 字节**，假设得到的值是 `0x2000`，这是 **PUD 表的物理地址**。

------

#### **步骤 2：从 PUD 表获取 PMD 表地址**

1. **访问 PUD 表**：PUD 表从物理地址 `0x2000` 开始。
2. **通过 PUD 索引计算偏移量**：
   - PUD 索引为 `0x001`，因此偏移量是：`0x001 * 8 = 0x8`。
   - **地址计算**：PUD 表地址 + 偏移量 = `0x2000 + 0x8 = 0x2008`。
3. **读取 PUD 表中的条目**：
   - 从 `0x2008` 处读取 **8 字节**，假设读取到的值是 `0x3000`，这是 **PMD 表的物理地址**。

------

#### **步骤 3：从 PMD 表获取 PTE 表地址**

1. **访问 PMD 表**：PMD 表从物理地址 `0x3000` 开始。
2. **通过 PMD 索引计算偏移量**：
   - PMD 索引为 `0x091`，因此偏移量是：`0x091 * 8 = 0x488`。
   - **地址计算**：PMD 表地址 + 偏移量 = `0x3000 + 0x488 = 0x3488`。
3. **读取 PMD 表中的条目**：
   - 从 `0x3488` 处读取 **8 字节**，假设读取到的值是 `0x4000`，这是 **PTE 表的物理地址**。

------

#### **步骤 4：从 PTE 表获取页帧地址**

1. **访问 PTE 表**：PTE 表从物理地址 `0x4000` 开始。
2. **通过 PTE 索引计算偏移量**：
   - PTE 索引为 `0x089`，因此偏移量是：`0x089 * 8 = 0x448`。
   - **地址计算**：PTE 表地址 + 偏移量 = `0x4000 + 0x448 = 0x4448`。
3. **读取 PTE 表中的条目**：
   - 从 `0x4448` 处读取 **8 字节**，假设读取到的值是 `0x80000`，这是 **物理页帧的基地址**。

------

#### **步骤 5：计算最终物理地址**

1. **从虚拟地址提取页内偏移**：偏移量为 `0xAB`。
2. **计算物理地址**：物理页帧基地址 + 页内偏移：

```
物理地址 = 0x80000 + 0xAB = 0x800AB
```

------

#### **总结：从虚拟地址到物理地址的路径**

1. **PGD**：从 `CR3` 获取 PGD 表地址，读取 PUD 表地址。
2. **PUD**：通过索引查找 PMD 表地址。
3. **PMD**：通过索引查找 PTE 表地址。
4. **PTE**：通过索引查找物理页帧地址。
5. **计算物理地址**：页帧地址 + 页内偏移。

------

#### **图示：虚拟地址到物理地址映射**

```
虚拟地址：0x0000_0123_4567_89AB  
+---> PGD (索引：0x000) ---> 物理地址：0x2000  
       +---> PUD (索引：0x001) ---> 物理地址：0x3000  
             +---> PMD (索引：0x091) ---> 物理地址：0x4000  
                   +---> PTE (索引：0x089) ---> 页帧地址：0x80000  
                         + 页内偏移：0xAB  
                         = 最终物理地址：0x800AB  
```

------

通过以上步骤，我们完整地展示了四级页表如何将虚拟地址转换为物理地址。每级页表通过 9 位索引定位下一层，直到 PTE 找到页帧基地址，加上页内偏移后得到最终的物理地址。

------

### 补充：寄存器存储在哪，PGD等这些表又存储在哪

#### **寄存器和页表存储的位置解析**

#### **1. 寄存器的存储位置**

寄存器是**CPU 内部的高速存储单元**，用于存储即将被处理的临时数据和指令。它们的特点是访问速度极快，但数量有限。常见的寄存器包括：

- **CR3 寄存器**：存储**页表的基地址**（PGD 表的物理地址）。
- **通用寄存器**：如 RAX、RBX、RCX 等，用于数据运算。
- **控制寄存器（CR0、CR2、CR3、CR4）**：存储与 CPU 控制、内存管理和分页相关的信息。

**总结**：寄存器存储在**CPU 内部**，在电路级别紧邻处理单元，以支持高速数据交换。

------

**2. 页表（PGD、PUD、PMD、PTE）的存储位置**

页表是用于虚拟内存管理的重要数据结构，用来建立**虚拟地址与物理地址之间的映射关系**。这些页表存储在**物理内存（RAM）**中。

- **PGD（Page Global Directory）**：
  存放在**物理内存**中，并通过 **CR3 寄存器**指向它的物理地址。
- **PUD、PMD、PTE**：
  这些表也存储在**物理内存**中，并通过各级页表条目提供的物理地址找到下一层页表。

------

#### **页表存储过程详解**

1. **CR3 寄存器**指向 PGD 表的物理地址。例如：`CR3 = 0x1000`。
2. **PGD 表**存放在 RAM 中的物理地址 `0x1000` 处。
3. **PGD 条目**中包含 PUD 表的物理地址。
4. **PUD 表**同样在 RAM 中某个位置存储，并在 **PGD 表条目**中找到它的地址。
5. **依次访问 PMD、PTE**，每一层表的地址都存储在上一层的表条目中，直到找到对应的物理页帧地址。

**总结**：PGD、PUD、PMD 和 PTE 等页表全部存储在**RAM**中，但它们的基地址通过分页硬件逐级查找，最终映射到物理地址。

------

#### **图示：CR3、页表与内存的关系**

```
[CPU]
  |-- CR3 (寄存器) --> [PGD] 物理地址：0x1000 (在 RAM 中)
                      |
                      +--> [PUD] 物理地址：0x2000 (在 RAM 中)
                            |
                            +--> [PMD] 物理地址：0x3000 (在 RAM 中)
                                  |
                                  +--> [PTE] 物理地址：0x4000 (在 RAM 中)
                                        |
                                        +--> 物理页帧地址：0x80000
```

------

#### **为什么页表存储在 RAM 中？**

1. **访问速度**：页表需要频繁查找（每次虚拟地址访问都要查页表），所以必须存储在**RAM**中。
2. **灵活性**：页表内容在系统运行时会不断更新（例如页面置换时），RAM 适合存储这种易变的数据。
3. **缓存机制**：为了减少每次访问 RAM 的开销，CPU 还会使用 **TLB（Translation Lookaside Buffer）** 缓存最近访问的页表项。

------

### **总结：寄存器与页表的存储位置**

- **寄存器**：存储在 CPU 内部（如 CR3 寄存器）。
- **PGD、PUD、PMD、PTE 页表**：存储在 **RAM** 中，通过 CR3 逐层查找每级表的地址，最终找到物理页帧地址。

------



### 补充：示例

假设一个虚拟地址 0x1234ABCD 映射到物理内存，具体步骤如下： 页号和偏移：将虚拟地址分解为虚拟页号和页内偏移，比如 0x1234A 是页号，BCD 是偏移。 查找页表：从 PGD 开始，逐级找到对应的 PTE。 读取 PPN：在 PTE 中，获取该虚拟页号对应的 PPN。 计算物理地址：将 PPN 和页内偏移组合，得到完整的物理地址。这个例子展开详细说说，包括每一个步骤

我们以具体的虚拟地址 `0x1234ABCD` 为例，详细展开虚拟地址到物理地址的转换过程。假设我们使用的是一个 4 级页表（典型的 64 位操作系统采用的多级页表结构），每级页表的大小和分段方式如下：

- 每个页表项（PTE）占用 8 字节（64 位），因此每个页表可以容纳 `2^9 = 512` 个 PTE。
- 虚拟地址分为 4 级：PGD（Page Global Directory），PUD（Page Upper Directory），PMD（Page Middle Directory）和 PTE（Page Table Entry）。
- 每级页表索引 9 位，共 `9 x 4 = 36` 位，再加上页内偏移 12 位，共 48 位地址。

### 假设条件

- 页大小为 4 KB，因此页内偏移占 12 位。
- 使用 4 级页表，每级页表索引为 9 位。
- 虚拟地址结构为 `PGD -> PUD -> PMD -> PTE -> 页内偏移`。

### 虚拟地址结构拆分

假设虚拟地址 `0x1234ABCD` 被表示为 48 位结构，我们可以从高位到低位依次拆分为：

```
虚拟地址：0x00001234ABCD
二进制：0000 0000 0000 0000 0001 0010 0011 0100 1010 1011 1100 1101
```

分段后结构如下（高位到低位）：

我们得到的每级页表索引和页内偏移如下：

1. **PGD 索引**（第 39 - 47 位）：`0x000`，二进制 `000000000`
2. **PUD 索引**（第 30 - 38 位）：`0x001`，二进制 `000000001`
3. **PMD 索引**（第 21 - 29 位）：`0x048`，二进制 `001001000`
4. **PTE 索引**（第 12 - 20 位）：`0x1AB`，二进制 `110101011`
5. **页内偏移**（第 0 - 11 位）：`0xBCD`，二进制 `110011011101`

### 正确的虚拟地址分解表

| 页表级别 | 位数范围      | 二进制值     | 十六进制值 |
| -------- | ------------- | ------------ | ---------- |
| PGD      | 第 39 - 47 位 | 000000000    | 0x000      |
| PUD      | 第 30 - 38 位 | 000000000    | 0x000      |
| PMD      | 第 21 - 29 位 | 010010001    | 0x091      |
| PTE      | 第 12 - 20 位 | 101001010    | 0x18A      |
| 页内偏移 | 第 0 - 11 位  | 101111001101 | 0xBCD      |

### 地址转换的步骤

#### 步骤 1：找到 PGD 表

1. **访问 PGD 表**：PGD 表是进程的顶级页表，内核通过 `CR3` 寄存器找到当前进程的页表根目录地址（即 PGD 表的起始地址）。
2. **从 PGD 表中获取 PUD 表地址**：根据 PGD 索引 `0x000`，在 PGD 表中找到第 0 项，这一项指向 PUD 表的基地址。

#### 步骤 2：找到 PUD 表

1. **访问 PUD 表**：使用从 PGD 表项中获得的 PUD 表地址。
2. **从 PUD 表中获取 PMD 表地址**：根据 PUD 索引 `0x001`，在 PUD 表中找到第 1 项，这一项指向 PMD 表的基地址。

#### 步骤 3：找到 PMD 表

1. **访问 PMD 表**：使用从 PUD 表项中获得的 PMD 表地址。
2. **从 PMD 表中获取 PTE 表地址**：根据 PMD 索引 `0x123`，在 PMD 表中找到第 291 项（十进制 291），这一项指向 PTE 表的基地址。

#### 步骤 4：找到 PTE 表

1. **访问 PTE 表**：使用从 PMD 表项中获得的 PTE 表地址。
2. **从 PTE 表中找到 PPN（物理页号）**：根据 PTE 索引 `0x04A`，在 PTE 表中找到第 74 项（十进制 74），这一项包含了虚拟页 `0x1234A` 所对应的物理页号（PPN）。

假设该物理页号为 `0x3F4`, 即表示物理内存中的第 `0x3F4` 页。

#### 步骤 5：计算物理地址

1. **页内偏移**：虚拟地址 `0x1234ABCD` 中低 12 位（`0xBCD`）为页内偏移，表示页内的具体偏移量。

2. **组合物理地址**：将物理页号 `0x3F4` 乘以页大小（4 KB），得到物理页的基地址，然后加上页内偏移。

   计算如下：

   - 物理页基地址 = `0x3F4 * 0x1000 = 0x3F4000`
   - 最终物理地址 = `0x3F4000 + 0xBCD = 0x3F4BCD`

因此，虚拟地址 `0x1234ABCD` 对应的物理地址为 `0x3F4BCD`。

### 总结

1. **虚拟地址分解**：将虚拟地址分解为 PGD、PUD、PMD、PTE 和页内偏移。
2. 逐级页表查找：
   - 从 PGD 开始，根据每级页表的索引依次找到下一级页表的地址，直到找到 PTE。
3. **获取 PPN**：在 PTE 中找到该虚拟页对应的物理页号（PPN）。
4. **计算物理地址**：将物理页号和页内偏移组合，得到最终物理地址。

通过这种逐级查找和映射，系统能够将虚拟地址转换为物理地址，实现内存的虚拟化管理。这种多级页表结构节省了内存空间，并支持内存保护和权限管理。

### 补充：按照 **9 位** 对应每级页表索引来进行划分

在这里，我们按照 **9 位** 对应每级页表索引来进行划分，而不是 **12 位**。因此，`0x000` 实际上只对应 **9 位二进制**（即 `000000000`），而不是 `12 位二进制`（即 `000000000000`）。

让我们重新确认一下分解的规则：

### 虚拟地址分解规则

假设我们在 4 级页表结构中使用 48 位虚拟地址空间，并按照以下方式分段：

- **PGD（Page Global Directory）**：9 位
- **PUD（Page Upper Directory）**：9 位
- **PMD（Page Middle Directory）**：9 位
- **PTE（Page Table Entry）**：9 位
- **页内偏移**：12 位

虚拟地址总共使用 **48 位**，因此我们有：

- `9 + 9 + 9 + 9 + 12 = 48` 位

### 解释 `0x000` 的二进制表示

在这种情况下，**每级页表索引占用 9 位**，因此：

- `0x000` 作为 PGD 索引时，只需转换为 **9 位的二进制数**。
- **0x000** 在 9 位二进制表示为 `000000000`。

如果我们将它扩展为 12 位，就会出现多余的 0，而每级页表的分段规则只需要 **9 位**。因此，`0x000` 在此情况下对应的二进制数是 `000000000`，并不是 `000000000000`。